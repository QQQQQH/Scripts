{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "classified-truck",
   "metadata": {},
   "source": [
    "### 输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-springer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "url = input('url:')\n",
    "url_prefix = re.match(r'(.*)AVED0_A0_L0_P', url).group()\n",
    "print(url_prefix)\n",
    "print()\n",
    "\n",
    "page_num = int(input('page_num:'))\n",
    "page_num_len = len(str(page_num - 1))\n",
    "print(page_num, page_num_len)\n",
    "print()\n",
    "\n",
    "\n",
    "book_name = input('book_name:')\n",
    "print(book_name)\n",
    "print()\n",
    "\n",
    "dirname_down = os.path.join('Rakuten_download', book_name)\n",
    "dirname_out = 'Rakuten_output'\n",
    "if not os.path.exists(dirname_down):\n",
    "    os.makedirs(dirname_down)\n",
    "if not os.path.exists(dirname_out):\n",
    "    os.makedirs(dirname_out)\n",
    "\n",
    "pagenums = [str(x).zfill(page_num_len) for x in range(page_num)]\n",
    "print(pagenums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_gen():\n",
    "    for pagenum in pagenums:\n",
    "        url = url_prefix + pagenum + '.pdf'\n",
    "        yield url, pagenum + '.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-boards",
   "metadata": {},
   "source": [
    "### 获取图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from urllib import request\n",
    "\n",
    "urls = url_gen()\n",
    "lock = threading.Lock()\n",
    "\n",
    "def loop_download():\n",
    "    while True:\n",
    "        try:\n",
    "            with lock:\n",
    "                url, filename = next(urls)\n",
    "        except:\n",
    "            break\n",
    "        try:\n",
    "            print('Downloading ', url)\n",
    "            with request.urlopen(url) as urlf:\n",
    "                with open(os.path.join(dirname_down, filename), 'wb') as f:\n",
    "                    f.write(urlf.read())\n",
    "        except:\n",
    "            print('Failed: ', url)\n",
    "            exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-defense",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thread_num = 20\n",
    "threads = []\n",
    "\n",
    "for i in range(thread_num):\n",
    "    t = threading.Thread(target=loop_download)\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "    \n",
    "\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-conditions",
   "metadata": {},
   "source": [
    "### 去除PDF文件头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "\n",
    "def get_jpg(filename_in, filename_out):\n",
    "    infile = open(os.path.join(dirname_down, filename_in), 'rb')\n",
    "    outfile = open(os.path.join(dirname_down, filename_out), 'wb')\n",
    "\n",
    "    # 读取文件头部，并查找 JPEG 文件头\n",
    "    hex_data = binascii.b2a_hex(infile.read(1500))\n",
    "    str_sidx = bytes.decode(hex_data).find('ffd8ff')\n",
    "    str_sidx = str_sidx // 2\n",
    "    # 确定位置后，重置文件指针至文件头部\n",
    "    infile.seek(0, 0)\n",
    "    # 切割文件\n",
    "    outfile.write(infile.read()[str_sidx:])\n",
    "    infile.close()\n",
    "    outfile.close() \n",
    "\n",
    "i = 0\n",
    "while i < len(pagenums):\n",
    "    if i == 0 or i == len(pagenums) - 1:\n",
    "        pagenum = pagenums[i]\n",
    "        filename_in = pagenum + '.pdf'\n",
    "        filename_out = pagenum + '.jpg'\n",
    "        get_jpg(filename_in, filename_out)\n",
    "        i = i + 1\n",
    "        continue\n",
    "    else:\n",
    "        j = i + 1\n",
    "        pagenum = [pagenums[x] for x in [i, j]]\n",
    "        filename_in = [x + '.pdf' for x in pagenum]\n",
    "        filename_out = [x + '.jpg' for x in reversed(pagenum)]\n",
    "        for x in range(2):\n",
    "            get_jpg(filename_in[x], filename_out[x])\n",
    "        i = i + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-church",
   "metadata": {},
   "source": [
    "### 压缩保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import zipfile\n",
    "\n",
    "for f in glob.glob(os.path.join(dirname_down, '*.pdf')):\n",
    "     os.remove(f)\n",
    "        \n",
    "def make_zip(source_dir, output_filename):\n",
    "    output_filename = output_filename + '.zip'\n",
    "    zipf = zipfile.ZipFile(output_filename, 'w', compression=zipfile.ZIP_DEFLATED)    \n",
    "    pre_len = len(os.path.dirname(source_dir))\n",
    "    for parent, dirname_downs, filenames in os.walk(source_dir):\n",
    "        for filename in filenames:\n",
    "            pathfile = os.path.join(parent, filename)\n",
    "            arcname = pathfile[pre_len:].strip(os.path.sep)     #相对路径\n",
    "            zipf.write(pathfile, arcname)\n",
    "    zipf.close()\n",
    "    print(output_filename)\n",
    "    \n",
    "make_zip(dirname_down, os.path.join(dirname_out, book_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-python385] *",
   "language": "python",
   "name": "conda-env-.conda-python385-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
